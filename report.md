# UAV and machine learning transform dike weakness detection

Thermal infrared imaging combined with deep learning now achieves **over 97% accuracy** for detecting seepage and piping in dikes, representing a paradigm shift from manual inspection methods that miss critical subsurface defects. The convergence of UAV technology, advanced sensors, and neural networks has created practical systems capable of inspecting hundreds of kilometers of flood defenses during active flood events—when traditional inspection is most dangerous and least feasible. While YOLO-family detectors dominate real-time applications with **92.7% precision** for piping detection,[0](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2024WR038931) Mask R-CNN delivers superior accuracy for pixel-level hazard mapping at **0.977 mAP** with processing times of just 15 milliseconds per image.[1](https://www.sciencedirect.com/science/article/abs/pii/S2212420924007441)[2](https://www.researchgate.net/publication/378784323_Multi-Level_Hazard_Detection_Using_a_UAV-Mounted_Multi-Sensor_for_Levee_Inspection) The field has matured rapidly since 2020, with Chinese and Dutch research programs producing validated systems now deployed on actual river dikes.

## Thermal imaging proves essential for detecting the invisible threats

Surface cracks represent only one dimension of dike vulnerability. The most dangerous failure modes—internal erosion, piping, and seepage—occur beneath the surface where visual inspection cannot reach. Research has demonstrated that thermal infrared cameras detect these hidden threats through temperature differentials: water infiltrating through a dike has higher specific heat capacity than surrounding soil, causing wet areas to retain heat longer during daytime and cool more gradually at night.[3](https://www.nature.com/articles/s41598-025-13258-y) Studies by Chen et al. (2024) collected **5,995 thermal infrared images** from four Chinese floodplains, training Mask R-CNN to categorize hazards into slope leakage, ground piping, and water piping with **98.2% recall**.[4](https://www.sciencedirect.com/science/article/abs/pii/S2212420924007441)

The spectral requirements vary dramatically by defect type. RGB cameras with **20+ megapixel resolution**[5](https://www.dslrpros.com/blogs/drone-trends/drone-infrastructure-inspection-for-bridges-roads-and-buildings) suffice for surface crack detection when achieving ground sampling distances (GSD) of **1.5-2.0 mm/pixel**—the threshold for reliably detecting cracks 2mm wide. However, moisture-related defects demand thermal sensors with minimum **640×512 pixel resolution** and temperature sensitivity below 0.03°C. Multispectral imaging adds value for vegetation stress monitoring that can indicate underlying moisture problems, while hyperspectral sensors enable detailed soil moisture quantification using green and red-edge spectral bands.[6](https://www.mdpi.com/1424-8220/25/3/782)

Flight altitude directly determines detection capability through the GSD equation. Detecting hairline cracks requires flying at **3-10 meters** altitude to achieve sub-2mm resolution, while thermal surveys for seepage detection can operate at **50-120 meters** since temperature anomalies manifest at larger spatial scales. The Dutch IJkdijk test facility has validated that combining low-altitude RGB passes with higher-altitude thermal sweeps optimizes both resolution and coverage efficiency.[7](https://link.springer.com/chapter/10.1007/978-90-481-2899-0_37)

## Resolution and overlap standards define data quality thresholds

Image acquisition standards have consolidated around consistent recommendations across research programs. For crack detection in infrastructure generally, the **GSD should be 3-5 times smaller** than the minimum defect size of interest. FAA research on airfield pavement established that orthophotos at **~1.5 mm/pixel** are "highly recommended" for reliable crack detection, with digital surface models at **~6 mm/pixel** sufficient for profile analysis.[8](https://fadron.com/pavement-inspection-with-drones-standards-precision-and-global-applications/) The practical detection limit sits around **0.05 mm/pixel** before image alignment algorithms begin failing.[9](https://www.mdpi.com/2078-2489/16/6/448)

Photogrammetric overlap requirements follow established guidelines: **75% frontal overlap and 75% side overlap** represent the professional standard,[10](https://www.aerotas.com/overlap-flight-pattern) increasing to **80-85% frontal and 70-75% side** for high-accuracy 3D reconstruction.[11](https://help.dronedeploy.com/hc/en-us/articles/22589691164183-What-is-the-recommended-front-and-side-overlap) Corridor mapping along linear infrastructure like dikes typically uses **85% frontal overlap** on single flight tracks.[12](https://support.pix4d.com/hc/en-us/articles/203756125)[13](https://www.researchgate.net/publication/360417003_Flood_Detection_Based_on_Unmanned_Aerial_Vehicle_System_and_Deep_Learning) Higher overlap compensates for featureless surfaces—common on earthen dikes—where automated feature matching algorithms struggle.[14](https://www.tandfonline.com/doi/full/10.1080/20909977.2022.2057148)

Temporal considerations prove critical for dike monitoring. Thermal imaging must occur under specific conditions: after sundown when solar loading has dissipated, with **minimum 10°C temperature differential** between wet and dry surfaces, humidity below 50%, and wind speeds under 12 mph.[15](https://www.sciencedirect.com/science/article/abs/pii/S2212420924007441)[16](https://www.roofingcontractor.com/articles/96973-advances-in-thermal-imaging-drone-technology-greatly-improve-commercial-flat-roof-inspection-efficiency) Seasonal timing matters as well—post-flood inspections during the dry season may expose normally submerged components, while vegetation at peak summer growth helps identify encroachment issues.

## YOLO dominates real-time detection while Mask R-CNN leads precision applications

The machine learning landscape for infrastructure defect detection has bifurcated into two dominant approaches. **YOLO-family architectures** (YOLOv5, YOLOv8, YOLOv11) deliver real-time performance essential for UAV-based inspection, processing images at **50+ frames per second** while achieving detection precision in the 85-93% range.[17](https://www.sciencedirect.com/science/article/pii/S1569843222001145) Duan et al. (2025) demonstrated YOLOv5 achieving **92.7% precision and 84.9% recall** for infrared piping detection across 104 field experiments covering diverse terrain including ponds, grasslands, and paddies.[18](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2024WR038931)

For applications demanding pixel-level accuracy, **Mask R-CNN** and U-Net variants set the standard. The Mask R-CNN implementation by Chen et al. for levee seepage detection achieved **mAP of 0.977** with **0.015-second inference time** per image—fast enough for near-real-time processing of large image datasets.[19](https://www.researchgate.net/publication/378784323_Multi-Level_Hazard_Detection_Using_a_UAV-Mounted_Multi-Sensor_for_Levee_Inspection) The model's Eigen-CAM visualization capability provides interpretability, showing inspectors exactly which image features triggered detection decisions.[20](https://www.sciencedirect.com/science/article/abs/pii/S2212420924007441)

Specialized architectures have emerged for embankment-specific challenges. The **U2Net-ECA-AS model** (Cheng et al., 2023) incorporates Efficient Channel Attention specifically designed for complex embankment backgrounds, achieving **IoU of 80.45% and F1-score of 88.88%** on UAV dike datasets.[21](https://www.sciencedirect.com/science/article/abs/pii/S2352012423001686) Transfer learning from building crack datasets to embankment applications has proven effective, with U²-Net_Aggregation reaching **90.06% F1-score** after domain adaptation.[22](https://www.sciencedirect.com/science/article/abs/pii/S2352012423017289)

Vision Transformers represent the emerging frontier, with hybrid CNN-Transformer architectures like **CT-crackseg** achieving 1.86% IoU improvement over pure CNN methods. The self-attention mechanism captures global context essential for detecting elongated crack patterns that span large image regions.[23](https://arxiv.org/html/2503.18082v1) However, transformers require more careful tuning and computational resources than established CNN approaches.

## Real-world deployments span from Dutch smart levees to US Army Corps operations

The Netherlands leads practical deployment through multiple coordinated programs. The **IJkdijk test facility**, operated by TNO, serves as a field laboratory for dike monitoring systems where sensor networks and deep learning algorithms are validated before operational deployment.[24](https://link.springer.com/chapter/10.1007/978-90-481-2899-0_37) FloodControl IJkdijk has developed "smart levees" with embedded sensors and automated monitoring,[25](http://dutchdikes.net/best-practice/) while **DDC Smart Inspections** received approval for beyond-visual-line-of-sight operations in the Port of Rotterdam in 2024 for dike mapping projects.[26](https://ddc.works/)

The US Army Corps of Engineers has integrated UAV inspection into standard operations. During the 2019 Midwest flooding, the Omaha District deployed drones to survey **over 500 miles of levees**, enabling rapid damage assessment during an active disaster when ground inspection was impossible.[27](https://www.army.mil/article/221378/corps_of_engineers_leveraging_drone_technology_to_capture_imagery_after_flooding_in_midwest) The Engineering Research and Development Center (ERDC) continues testing UAV LiDAR systems for creating digital twins of levee infrastructure, enabling change detection over time.[28](https://www.erdc.usace.army.mil/Media/Video-Page/videoid/771897/)[29](https://gaorfid.com/rfid-ble-iot-drones-for-dam-and-water-control-construction-industry/)

Chinese research programs have contributed the largest validated datasets.[30](https://www.sciencedirect.com/science/article/abs/pii/S2212420924007441) Wang et al. (2022) developed a CNN with auxiliary temperature input specifically designed to overcome interference problems in complex infrared dam-surface backgrounds, validated on full-scale embankment dams.[31](https://www.sciencedirect.com/science/article/abs/pii/S0924271624003770)[32](https://www.sciencedirect.com/science/article/abs/pii/S2212420924007441)[33](https://www.sciencedirect.com/science/article/abs/pii/S095006182200109X) Zhou et al. (2024) tested **13 different YOLO detector versions** plus Faster R-CNN, SSD, and RetinaNet on actual river dike sites using multiple thermal imager models (Testo-869, FLIR T1050sc, FLIR Duo Pro-R).[34](https://www.sciencedirect.com/science/article/abs/pii/S0924271624003770)

## Bridge and building inspection achieve higher accuracy with simpler requirements

Cross-domain comparison reveals that dike inspection presents unique challenges not found in building or bridge applications. Bridge crack detection using **Faster R-CNN with VGG16 backbone** achieves **92.03% precision and 96.26% recall**—[35](https://www.sciencedirect.com/science/article/abs/pii/S0950061822033153)significantly higher than typical dike results—because concrete surfaces offer more consistent texture and defects present clearer visual signatures. The CODEBRIM benchmark dataset enables direct model comparison across five defect classes: cracks, spallation, exposed rebar, efflorescence, and corrosion.[36](https://www.sciencedirect.com/science/article/pii/S2090447923001867)

State DOT case studies demonstrate dramatic cost savings. Michigan DOT reduced bridge inspection from **8 hours and $4,600** (traditional 2-person crew) to **1 hour and ~$1,200** using UAVs—a 75% cost reduction. Maine DOT used drones in combination with under-bridge inspection trucks to identify spalling and loose concrete while minimizing safety hazards.[37](https://www.nationalacademies.org/read/27903/chapter/6) The market for UAS bridge inspection is projected to grow at **21.4% CAGR** over the next decade according to Fact MR analysis.[38](https://www.skydio.com/blog/drones-transform-bridge-inspections)

Building facade inspection benefits from thermal-visible fusion. Research in Shenzhen on high-density residential communities demonstrated that combining RGB and thermal UAV imaging with deep learning enables detection of both surface cracks (**87.86% mIoU**) and subsurface leakage (**79.05% mIoU**). Optimal inspection distances vary by building height: **5-10 meters** for low-rise structures, **20-25 meters** for high-rise facades.[39](https://pmc.ncbi.nlm.nih.gov/articles/PMC12694060/)[40](https://www.mdpi.com/1424-8220/25/23/7118)

## Pavement applications demonstrate the highest detection speeds and largest datasets

Road and pavement defect detection has generated the most extensive benchmark datasets and highest inference speeds of any infrastructure domain. The **RDD2020 dataset** contains over 26,000 images with 31,000+ annotated damage instances collected across Japan, India, and Czech Republic. The Global Road Damage Detection Challenge attracted 59 teams from 14 countries, establishing standardized evaluation protocols.

Detection performance on pavement reaches **mAP50 of 92.4%** with specialized YOLO variants (YOLOv8-DGS), processing at **85 frames per second**.[41](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0324512)[42](https://pmc.ncbi.nlm.nih.gov/articles/PMC12097708/) The **PCTNet** transformer-based architecture achieves **95.89% precision and 90.53% mIoU**[43](https://www.researchgate.net/figure/Exemplary-pavement-images-from-the-presented-GAPs-dataset-with-different-types-and-levels_fig1_318327801) for semantic segmentation of crack pixels. These numbers exceed dike detection performance partly because pavement defects present as well-defined visual features against relatively uniform backgrounds.

UAV-based pavement inspection offers compelling advantages over traditional ground vehicle surveys.[44](https://thedronelifenj.com/drones-for-road-highway-construction/)[45](https://dl.acm.org/doi/fullHtml/10.1145/3594806.3596561)[46](https://arxiv.org/pdf/2308.00828) A coordinated Kuwait highway program mapped **1,000 kilometers in 6 weeks** with **40% cost reduction**. Paris Charles de Gaulle Airport inspected 200,000 square meters of runway at **1.5 mm/pixel resolution** in under two hours. Carbon emissions drop by approximately **99%** compared to traditional vehicle-based surveys—from ~40 kg CO2 per cycle to ~0.25 kg per drone flight.

## Key technical differences emerge across infrastructure domains

The fundamental difference between dike inspection and other infrastructure domains lies in defect visibility. Building cracks, bridge spalling, and pavement potholes present as surface-visible features detectable through standard RGB imaging. Dike failures often initiate through **internal erosion and piping**—processes invisible to visual sensors until catastrophic breach is imminent.[47](https://www.mdpi.com/2072-4292/17/20/3398)[48](https://www.nature.com/articles/s41598-025-13258-y)[49](https://www.researchgate.net/publication/378784323_Multi-Level_Hazard_Detection_Using_a_UAV-Mounted_Multi-Sensor_for_Levee_Inspection) This explains why thermal infrared is essential for dike monitoring but optional for most other applications.

| Domain | Primary Sensor | Critical Defects | Best Model | Typical Accuracy |
|--------|---------------|------------------|------------|------------------|
| **Dikes/Levees** | Thermal IR + RGB | Seepage, piping, cracks | Mask R-CNN | mAP 97.7% |
| **Bridges** | RGB | Cracks, spalling, corrosion | Faster R-CNN | F1 94.1% |
| **Buildings** | RGB + Thermal | Cracks, moisture, thermal | Knet/CNN | mIoU 87.9% |
| **Pavement** | RGB | Cracks, potholes, rutting | YOLOv8-DGS | mAP 92.4% |

Data scarcity poses a more severe constraint for dike applications.[50](https://www.sciencedirect.com/science/article/abs/pii/S2352012423017289) While pavement datasets contain tens of thousands of annotated images, dike-specific datasets rarely exceed a few thousand images. This has driven innovation in transfer learning and synthetic data generation—including DreamBooth Diffusion Models for creating synthetic sand boil images.[51](https://ieee-dataport.org/keywords/sand-boil-detection)

## Current limitations center on generalization and real-time edge processing

Despite impressive laboratory performance, several challenges limit operational deployment. Models trained on dike imagery from single locations achieve accuracy exceeding 94%, but **generalization across diverse sites remains problematic**.[52](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2024WR038931) Weather conditions significantly impact thermal detection—continuous rain reduces temperature differentials that enable seepage identification.[53](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2024WR038931)[54](https://www.sciencedirect.com/science/article/abs/pii/S2212420924007441) Vegetation covering dike slopes occludes visual inspection while only partially transparent to thermal imaging.[55](https://www.sciencedirect.com/science/article/abs/pii/S2212420924007441)

Computational requirements for real-time onboard processing remain challenging. While lightweight models like **CrackScopeNet** achieve state-of-the-art segmentation with only **1.05 million parameters**,[56](https://www.mdpi.com/2504-446X/8/9/417) most high-accuracy architectures require post-flight processing on dedicated hardware. Edge deployment on NVIDIA Jetson platforms achieves **25-60 FPS** for optimized models, but the most accurate segmentation networks still demand server-class GPUs.[57](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2024WR038931)

Regulatory constraints limit operational flexibility. Beyond-visual-line-of-sight (BVLOS) operations require special waivers in most jurisdictions, restricting autonomous inspection of long linear infrastructure. The Netherlands and United States have made progress on BVLOS authorization, but regulatory frameworks lag technological capability in most regions.

## Research from 2023-2025 has delivered breakthrough capabilities

Recent advances have addressed multiple longstanding limitations. Duan et al.'s 2025 publication in Water Resources Research represents the first comprehensive UAV-based piping detection system validated across **104 field experiments at 12 different sites**, demonstrating robust performance across ponds, grasslands, paddies, and bare land.[58](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2024WR038931) The study established that infrared detection significantly outperforms visible-spectrum approaches for subsurface anomalies (**precision 92.7% vs 70.4%**).[59](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2024WR038931)

Multi-modal fusion has matured substantially. Systems combining thermal infrared, RGB, and LiDAR now provide comprehensive assessment capabilities—thermal for moisture detection, RGB for surface cracks, and LiDAR for 3D deformation measurement.[60](https://www.tandfonline.com/doi/full/10.1080/17538947.2025.2528617)[61](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2024WR038931)[62](https://www.mdpi.com/1996-1073/19/1/5)[63](https://www.researchgate.net/publication/362079923_Automatic_recognition_of_earth_rock_embankment_leakage_based_on_UAV_passive_infrared_thermography_and_deep_learning)[64](https://www.mdpi.com/2504-446X/8/3/90) The integration of **Segment Anything Model (SAM)** with YOLO detectors has enabled multi-damage segmentation with minimal task-specific training.

Foundation model adaptation represents the emerging research frontier. Vision transformers pre-trained on massive image datasets show promise for zero-shot defect detection, potentially addressing the data scarcity challenge that has limited dike-specific model development. Self-supervised and semi-supervised learning approaches increasingly enable training with limited labeled data.

## Conclusion

UAV-based machine learning for dike weakness detection has transitioned from research concept to operational reality, with multiple validated systems now deployed on actual flood defense infrastructure. The technology stack has stabilized around thermal infrared imaging for seepage detection combined with RGB for surface defects, processed through YOLO architectures for real-time applications or Mask R-CNN for precision mapping. Detection accuracy exceeds **90%** for major defect classes under favorable conditions, with inference speeds enabling processing of thousands of images per inspection mission.

The most significant remaining challenges are domain generalization—ensuring models trained in one region perform reliably elsewhere—and regulatory approval for autonomous BVLOS operations that would unlock efficient inspection of long linear infrastructure. The integration of foundation models and multi-modal sensor fusion represents the near-term research frontier, with potential to achieve robust performance across diverse conditions while reducing training data requirements. For organizations managing dike infrastructure, the technology is mature enough for operational deployment, with the Dutch and Chinese programs providing validated implementation models.